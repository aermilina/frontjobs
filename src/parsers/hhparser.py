import aiohttp
import logging
import os
from datetime import datetime, timedelta
from typing import List, Tuple, Optional, Dict
from dateparser import parse
from src.utils.lastpublished import save_last_published_date
from src.utils.dateutils import to_utc, is_newer, update_last_published_date
from src.parsers.base_parser import VacancyParser
from src.utils.cleandescription import cleandescription



# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
logging.basicConfig(
    level=getattr(logging, log_level, logging.INFO),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

class HHParser(VacancyParser):
    def __init__(
        self,
        url: str,
        last_published_date: Optional[datetime],
        last_published_file: str
    ):
        super().__init__(last_published_date, last_published_file)
        self.api_url = url
        self.search_text = 'frontend'
        self.schedule = 'remote'

    async def fetch_vacancies(self) -> List[Tuple[str, str, Dict]]:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸ Ğ¸Ğ· API HeadHunter Ñ Ğ¿Ğ°Ğ³Ğ¸Ğ½Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¸ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµÑ‚ Ğ¸Ñ… Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ.
        """
        vacancies = []
        new_last_published_date = self.last_published_date

        if not self.api_url:
            logger.error("HH_API_URL Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½ Ğ² .env")
            return []

        # Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ´Ğ°Ñ‚Ñƒ Ğ·Ğ° Ğ²Ñ‡ĞµÑ€Ğ°
        yesterday = (datetime.now() - timedelta(days=1)).isoformat()
        logger.info(f"Ğ”Ğ°Ñ‚Ğ° Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ğ¾Ğ¸ÑĞºĞ°: {yesterday}")
        logger.debug(f"ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ğ°Ñ Ğ´Ğ°Ñ‚Ğ°: {self.last_published_date}")

        params = {
            "text": self.search_text,
            "search_field": "name",
            "schedule": self.schedule,
            "date_from": yesterday,
            "per_page": 100
        }

        async with aiohttp.ClientSession() as session:
            page = 0
            while True:
                params["page"] = page
                logger.info(f"Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº API HeadHunter: {self.api_url}, ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° {page}, params={params}")
                try:
                    async with session.request('GET',self.api_url, params=params, ssl=False, timeout=10) as response:
                        response.raise_for_status()
                        data = await response.json()
                except aiohttp.ClientResponseError as e:
                    logger.error(f"HTTP-Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ API {self.api_url}: {e.status}, {e.message}")
                    return []
                except aiohttp.ClientError as e:
                    logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ API {self.api_url}: {e}")
                    if "SSL" in str(e):
                        logger.warning("SSL-Ğ¾ÑˆĞ¸Ğ±ĞºĞ°. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° SSL Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞµÑ€Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ñ‹.")
                    return []
                except ValueError as e:
                    logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ JSON Ğ¾Ñ‚ {self.api_url}: {e}")
                    return []

                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
                if data is None:
                    logger.error("ĞÑ‚Ğ²ĞµÑ‚ API Ñ€Ğ°Ğ²ĞµĞ½ None")
                    return []
                items = data.get('items', [])
                logger.debug(f"ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾ {len(items)} Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ {page}")
                if not isinstance(items, list) or not items:
                    logger.info(f"ĞĞµÑ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ {page}")
                    break

                for item in items:
                    title = item.get('name' ) or ''
                    snippet = item.get('snippet') or {}
                    raw_description = snippet.get('responsibility') or snippet.get('requirement') or ''
                    employer = item.get('employer') or {}
                    company = employer.get('name', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾')
                    salary_data = item.get('salary') or {}
                    salarymin = salary_data.get('from', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾')
                    salarymax = salary_data.get('to', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾')
                    currency = salary_data.get('currency', '')
                    pub_date_str = item.get('published_at', '')
                    experience_data = item.get('experience') or {}
                    experience = experience_data.get('name', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾')
                    link = item.get('alternate_url', '#')

                    # Ğ”ĞµĞ±Ğ°Ğ³
                    logger.debug(f"Ğ’Ğ°ĞºĞ°Ğ½ÑĞ¸Ñ '{title}': salarymin={salarymin}, salarymax={salarymax}, currency={currency}, published_at={pub_date_str}")
                    description = cleandescription(raw_description)

                    # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ñ‹
                    if salary_data:
                        if salarymin and salarymax:
                            salary = f"{salarymin}â€“{salarymax} {currency}"
                        elif salarymin:
                            salary = f"from {salarymin} {currency}"
                        elif salarymax:
                            salary = f"to {salarymax} {currency}"
                        else:
                             salary = f"Not specified"
                    else:
                        salary = "Not specified"

                  

                    # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ´Ğ°Ñ‚Ñ‹
                    date_published = None
                    if pub_date_str:
                        try:
                            parsed_date = parse(pub_date_str, settings={'TIMEZONE': 'UTC', 'TO_TIMEZONE': 'UTC'})
                            if parsed_date:
                                date_published = to_utc(parsed_date)
                                formatted_date = date_published.strftime('%d %B %Y')
                            else:
                                logger.warning(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°Ğ·Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ´Ğ°Ñ‚Ñƒ: {pub_date_str}")
                        except Exception as e:
                            logger.warning(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ´Ğ°Ñ‚Ñ‹: {pub_date_str}, {e}")
                      # ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
                    metadata = {
                        "description": description[:100] + "..." if len(description) > 100 else description,
                        "experience": experience,
                        "company": company,
                        "published_date": date_published.strftime('%Y-%m-%d %H:%M:%S'),
                        "published_date_str": formatted_date,
                        "salary": salary
                    }

                    # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ
                    if date_published and is_newer(date_published, self.last_published_date):
                        vacancies.append((title, link, metadata))
                        new_last_published_date = update_last_published_date(new_last_published_date, date_published)
                        logger.info(f"Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ñ: {title}, {link}")
                    else:
                        logger.debug(f"Ğ’Ğ°ĞºĞ°Ğ½ÑĞ¸Ñ '{title}' Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ° Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ: date_published={date_published}, last_published_date={self.last_published_date}")

                page += 1

        if new_last_published_date:
            self.last_published_date = new_last_published_date
            save_last_published_date(new_last_published_date, self.last_published_file)

        logger.info(f"Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹: {len(vacancies)}")
        return vacancies

    def format_message(self, title: str, link: str, metadata: Dict) -> str:
        """
        Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Telegram.
        """
        return (
            f"ğŸ’¼ **{title}**\n\n"
            f"ğŸ“… Published: {metadata['published_date_str']}\n\n"
            f"âŒ›ï¸ Experience: {metadata['experience']}\n\n"
            f"ğŸ¢ Company: {metadata['company']}\n\n"
            f"ğŸ“ Description: {metadata['description']}\n\n"
            f"ğŸ’µ Salary: {metadata['salary']}\n\n"
            f"ğŸ‘‰[APPLY NOW]({link})"
        )